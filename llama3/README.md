### Llama 3 from Meta AI

This one is exciting and i think everyone knows this one besides GPT.

On April 2024 META releasd llama3 to everyone. Since than it's been rigoursly used by so many machine learning experts in prompts, audio and image processing. It's by far the most compact model that's getting close to gpt-4 while be smaller in size with params and lower consumption processing, which makes it ideal for groups and communities on open source, unlike closed source in orginizations. Now, there is 1 set back with llama3, you need to refine it's parameters a bit with tuning in order to make it either more general or factual on response depending on your goal, so it doesn't come like pre-tuned as all the models in here besides bloom, to your need. Even that it's not being properly tuned, it's still good at capturing context and a response without specific configuration in tuning, which shows it's potential. Furthermore, it's really good when you tune it. So far, llama3 is the 2nd best LLM to use right now, just behind gpt-4.

In my view, these both have strengths and weakness's, the advantage I see with llama3 over GPT4 is it's versatility with developers when it comes to training, tuning and optimizing to any task. GPT-4o since it's a closed source model from openai.. Despite there name, isn't as simple in retraining and configuring compared to in llama3. 

This is what makes LLama3 prefereable in a more open developer scenario in my view, especially when it comes to configuration and retraining, llama3 is significantly cheaper and easier in training and optimizing compared to in gpt-4


But gpt-4 like we all know is right now the best when it comes to text generation. It's the best at interacting with the users question based on it's modification around the transformer and algorithm compared to other models, so if you are not going to do retraining or optimizing as much, i'd say gpt-4o is better and cheaper than whatever option there is right now, but i do recommend nonetheless to still use a lot llama3, because you should get into training and optmizing the model during testing and validation as that's a very necessary skill to have in machine learning.
